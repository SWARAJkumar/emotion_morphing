{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sad\n",
      "happy\n",
      "neutral\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('ydata', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "for key in data:\n",
    "    print(key)\n",
    "\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 65815)\n"
     ]
    }
   ],
   "source": [
    "print(data['happy'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "x = data['neutral']\n",
    "y = data['happy']\n",
    "z = data['sad']\n",
    "\n",
    "x_train = np.concatenate((y[:380],z[:380]))\n",
    "X_train = np.concatenate((x[:380],x[:380]))\n",
    "\n",
    "noisy_x= x_train+np.random.normal(np.mean(x_train), 0.003,x_train.shape)\n",
    "\n",
    "x_train = np.concatenate((x_train, noisy_x))\n",
    "X_train = np.concatenate((x[:380],x[:380],x[:380],x[:380]))\n",
    "\n",
    "noisy_x= x_train+np.random.normal(np.mean(x_train), 0.001,x_train.shape)\n",
    "\n",
    "x_train = np.concatenate((x_train, noisy_x))\n",
    "X_train = np.concatenate((x[:380],x[:380],x[:380],x[:380]))\n",
    "\n",
    "noisy_x= x_train+np.random.normal(np.mean(x_train), 0.004,x_train.shape)\n",
    "\n",
    "x_train = np.concatenate((x_train, noisy_x))\n",
    "X_train = np.concatenate((x[:380],x[:380],x[:380],x[:380]))\n",
    "\n",
    "x_val=np.concatenate((y[380:399],z[380:399]))\n",
    "X_val=np.concatenate((x[380:399],x[380:399]))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(X_train.shape)\n",
    "\n",
    "from IPython.lib.display import Audio\n",
    "Audio(noisy_x[380], rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "####ENCODER\n",
    "from keras.layers import Input, Dense, Conv1D\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "\n",
    "# encoding_dim = 512\n",
    "\n",
    " \n",
    "# input_img = Input(shape=(65815,))\n",
    "# # add a Dense layer with a L1 activity regularizer\n",
    "# encoded = Dense(encoding_dim, activation='relu',\n",
    "#                 activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "# ecoded= Dense(256, activation='relu', activity_regularizer=regularizers.l1(10e-5))(encoded)\n",
    "# decoded= Dense(512, activation='relu', activity_regularizer=regularizers.l1(10e-5))(encoded)\n",
    "# decoded = Dense(65815)(decoded)\n",
    "\n",
    "# autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xyz= optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "autoencoder.compile(optimizer=xyz, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "autoencoder.fit(x_train, X_train,\n",
    "                epochs=10,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val, X_val)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io.wavfile\n",
    "sample_rate, signal = scipy.io.wavfile.read(\"new2.wav\")\n",
    "print(np.min(signal), np.max(signal), sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generated_neutral = (data['sad'][122].reshape((1, 65815)))\n",
    "print(np.min(generated_neutral), np.max(generated_neutral))\n",
    "generated_neutral = autoencoder.predict(data['sad'][280].reshape((1, 65815,1)))\n",
    "sr=22050\n",
    "from IPython.display import Audio\n",
    "Audio(generated_neutral, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original= data['sad'][122].reshape((1,65815))\n",
    "Audio(original, rate=22050)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling1D, Flatten\n",
    "import keras.layers\n",
    "input_img = Input(shape=(65815,1))\n",
    "# add a Dense layer with a L1 activity regularizer\n",
    "encoded = Conv1D(16, (80), strides=1, activation='relu')(input_img)\n",
    "encoded= MaxPooling1D(pool_size=4, strides=None, padding='valid')(encoded)\n",
    "encoded = Conv1D(32, (10), strides=1, activation='relu')(encoded)\n",
    "encoded= MaxPooling1D(pool_size=4, strides=None, padding='valid')(encoded)\n",
    "encoded = Conv1D(64, (6), strides=1, activation='relu')(encoded)\n",
    "encoded= MaxPooling1D(pool_size=4, strides=None, padding='valid')(encoded)\n",
    "encoded = Conv1D(128, (6), strides=1, activation='relu')(encoded)\n",
    "encoded= MaxPooling1D(pool_size=2, strides=None, padding='valid')(encoded)\n",
    "encoded= Flatten ()(encoded)\n",
    "encoded= Dense(512, activation='relu', activity_regularizer=regularizers.l1(10e-5))(encoded)\n",
    "decoded = Dense(65815)(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xyz= optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "autoencoder.compile(optimizer=xyz, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_new= x_train.reshape(760,65815,1)\n",
    "x_val_new= x_val.reshape(x_val.shape[0],65815,1)\n",
    "print(x_train_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train_new, X_train,\n",
    "                epochs=10,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val_new, X_val)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generated_neutral = (data['sad'][222].reshape((1, 65815)))\n",
    "print(np.min(generated_neutral), np.max(generated_neutral))\n",
    "generated_neutral = autoencoder.predict(data['sad'][280].reshape((1, 65815,1)))\n",
    "sr=22050\n",
    "from IPython.display import Audio\n",
    "Audio(generated_neutral, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original= data['sad'][222].reshape((1,65815))\n",
    "Audio(original, rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####DECODERS NOW\n",
    "\n",
    "encoding_dim = 2048\n",
    "\n",
    "\n",
    "input_img = Input(shape=(25800,))\n",
    "# add a Dense layer with a L1 activity regularizer\n",
    "encoded = Dense(encoding_dim, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "decoded = Dense(25800)(encoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##HAPPY DECODER\n",
    "\n",
    "\n",
    "\n",
    "happydecoder = Model(input_img, decoded)\n",
    "\n",
    "\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoderh = Model(input_img, encoded)\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_inputh = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layerh = happydecoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoderh = Model(encoded_inputh, decoder_layerh(encoded_inputh))\n",
    "\n",
    "happydecoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "\n",
    "\n",
    "#neutral x_train=\n",
    "#happy X_train=\n",
    "\n",
    "X_train = np.concatenate((y[:180],y[200:380],y[400:580],y[600:780],y[800:980],y[1000:1180],y[1200:1380],y[1400:1580],y[1600:1780],y[1800:1980],y[2000:2180],y[2200:2380]))\n",
    "x_train = np.concatenate((x[:180],x[200:380],x[400:580],x[600:780],x[800:980],x[1000:1180],x[1200:1380],x[1400:1580],x[1600:1780],x[1800:1980],x[2000:2180],x[2200:2380]))\n",
    "\n",
    "happydecoder.fit(x_train, X_train,\n",
    "                epochs=10,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "               )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##SAD DECODER\n",
    "\n",
    "\n",
    "\n",
    "saddecoder = Model(input_img, decoded)\n",
    "\n",
    "\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoders = Model(input_img, encoded)\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_inputs = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layers = saddecoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoders = Model(encoded_inputs, decoder_layers(encoded_inputs))\n",
    "\n",
    "saddecoder.compile(optimizer='adadelta', loss='mean_squared_error')\n",
    "\n",
    "\n",
    "#neutral x_train=\n",
    "#sad X_train=\n",
    "\n",
    "X_train = np.concatenate((z[:180],z[200:380],z[400:580],z[600:780],z[800:980],z[1000:1180],z[1200:1380],z[1400:1580],z[1600:1780],z[1800:1980],z[2000:2180],z[2200:2380]))\n",
    "x_train = np.concatenate((x[:180],x[200:380],x[400:580],x[600:780],x[800:980],x[1000:1180],x[1200:1380],x[1400:1580],x[1600:1780],x[1800:1980],x[2000:2180],x[2200:2380]))\n",
    "\n",
    "saddecoder.fit(x_train, X_train,\n",
    "                epochs=10,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "               )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###TEST HAPPY TO SAD\n",
    "\n",
    "#test btw 380-399,580-599,..........,2380-2399\n",
    "\n",
    "xy = data['Happy'][390].reshape((1, 25800))\n",
    "#in encoder\n",
    "encodermid = encoder.predict(xy)\n",
    "encoderout = decoder.predict(encodedmid)\n",
    "\n",
    "#pushing to SAD decoder\n",
    "decodermid=encoders.predict(encoderout)\n",
    "mfccs=decoders.predict(decodermid)\n",
    "\n",
    "\n",
    "print(mfccs)\n",
    "\n",
    "print(mfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "# import numpy as np\n",
    "from IPython.lib.display import Audio\n",
    "\n",
    "def invlogamplitude(S):\n",
    "    \"\"\"librosa.logamplitude is actually 10_log10, so invert that.\"\"\"\n",
    "    return 10.0**(S/10.0)\n",
    "\n",
    "# filename = \"a.wav\"\n",
    "# y, sr = librosa.load(filename)\n",
    "\n",
    "# Y = librosa.stft(y)\n",
    "# mfccs = librosa.feature.mfcc(y, n_mfcc=100)\n",
    "def recon(mfccs):\n",
    "    sr = 22050\n",
    "\n",
    "    n_mfcc = mfccs.shape[0]\n",
    "    n_mel = 128\n",
    "    dctm = librosa.filters.dct(n_mfcc, n_mel)\n",
    "    n_fft = 2048\n",
    "    mel_basis = librosa.filters.mel(sr, n_fft)\n",
    "\n",
    "    bin_scaling = 1.0/np.maximum(0.0005, np.sum(np.dot(mel_basis.T, mel_basis),\n",
    "    axis=0))\n",
    "\n",
    "    recon_stft = bin_scaling[:, np.newaxis] * np.dot(mel_basis.T,\n",
    "    invlogamplitude(np.dot(dctm.T, mfccs)))\n",
    "\n",
    "    excitation = np.random.randn(mfccs.shape[1] * 510)\n",
    "    E = librosa.stft(excitation)\n",
    "    recon = librosa.istft(E/np.abs(E)*np.sqrt(recon_stft))\n",
    "\n",
    "    print(mfccs.shape)\n",
    "    return Audio(recon, rate=sr)\n",
    "    #librosa.output.write_wav('test.wav', recon, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recon(data['Happy'][5].reshape((200, 129), order='F'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recon(data['Neutral'][5].reshape((200,129),order='F'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mxx = data['Sad'][355].reshape((200, 129), order='F')\n",
    "# mxx = mxx * divx\n",
    "# mxx += np.min(data['neutral'])\n",
    "\n",
    "recon(mxx)\n",
    "# recon(mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generated_neutral = autoencoder.predict(data['Sad'][355].reshape((1, 25800)))\n",
    "mfccs=generated_neutral.reshape((200,129),order='F')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myy = mfccs.reshape((200, 129), order='F')\n",
    "# myy = myy * divy\n",
    "# myy += np.min(data['happy'])\n",
    "\n",
    "recon(2*myy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "model= autoencoder \n",
    "model_json = model.to_json()\n",
    "with open(\"dense_final.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "print(\"json file made\")\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"dense_final.h5py\")\n",
    "print(\"Saved model to disk\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 4 from 1 for 'max_pooling3d_1/MaxPool3D' (op: 'MaxPool3D') with input shapes: [?,110,220,1,16].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\swaraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    672\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\swaraj\\appdata\\local\\programs\\python\\python35\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\swaraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 4 from 1 for 'max_pooling3d_1/MaxPool3D' (op: 'MaxPool3D') with input shapes: [?,110,220,1,16].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f0c98bb7f7e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# add a Dense layer with a L1 activity regularizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mencoded\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mMaxPooling3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mencoded\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\swaraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[1;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\swaraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    321\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m                                         data_format=self.data_format)\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\swaraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36m_pooling_function\u001b[1;34m(self, inputs, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[0;32m    379\u001b[0m                           padding, data_format):\n\u001b[0;32m    380\u001b[0m         output = K.pool3d(inputs, pool_size, strides,\n\u001b[1;32m--> 381\u001b[1;33m                           padding, data_format, pool_mode='max')\n\u001b[0m\u001b[0;32m    382\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\swaraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mpool3d\u001b[1;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[0;32m   3416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3417\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'max'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3418\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3419\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'avg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3420\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavg_pool3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\swaraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool3d\u001b[1;34m(input, ksize, strides, padding, name)\u001b[0m\n\u001b[0;32m   1623\u001b[0m   \"\"\"\n\u001b[0;32m   1624\u001b[0m   result = _op_def_lib.apply_op(\"MaxPool3D\", input=input, ksize=ksize,\n\u001b[1;32m-> 1625\u001b[1;33m                                 strides=strides, padding=padding, name=name)\n\u001b[0m\u001b[0;32m   1626\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\swaraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    761\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    762\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    764\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\swaraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2327\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2328\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2329\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2330\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2331\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\swaraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1715\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1717\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1718\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1719\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32mc:\\users\\swaraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1666\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1667\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1669\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\swaraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[0;32m    611\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\swaraj\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 4 from 1 for 'max_pooling3d_1/MaxPool3D' (op: 'MaxPool3D') with input shapes: [?,110,220,1,16]."
     ]
    }
   ],
   "source": [
    "from keras.layers import MaxPooling3D, Flatten,Conv3D\n",
    "import keras.layers\n",
    "input_img = Input(shape=(224,224,3,1))\n",
    "# add a Dense layer with a L1 activity regularizer\n",
    "encoded = Conv3D(16, (5,5,3), strides=(2,1,1), activation='relu')(input_img)\n",
    "encoded= MaxPooling3D(pool_size=4, strides=None, padding='valid')(encoded)\n",
    "encoded = Conv2D(32, (5,5), strides=(2,1), activation='relu')(encoded)\n",
    "encoded= MaxPooling2D(pool_size=4, strides=None, padding='valid')(encoded)\n",
    "encoded = Conv2D(64, (6), strides=1, activation='relu')(encoded)\n",
    "encoded= MaxPooling2D(pool_size=4, strides=None, padding='valid')(encoded)\n",
    "encoded = Conv2D(128, (6), strides=1, activation='relu')(encoded)\n",
    "encoded= MaxPooling2D(pool_size=2, strides=None, padding='valid')(encoded)\n",
    "encoded= Flatten ()(encoded)\n",
    "encoded= Dense(512, activation='relu', activity_regularizer=regularizers.l1(10e-5))(encoded)\n",
    "decoded = Dense(65815)(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
